<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>Peter Bouda - AI</title><link>https://www.peterbouda.eu/</link><description>Natural Language Processing Consultant</description><lastBuildDate>Wed, 15 Oct 2025 16:47:00 +0100</lastBuildDate><item><title>Running AI atÂ home</title><link>https://www.peterbouda.eu/running-ai-at-home.html</link><description>&lt;p&gt;The first reviews of &lt;span class="caps"&gt;NVIDIA&lt;/span&gt; &lt;span class="caps"&gt;DGX&lt;/span&gt; Spark review are being published, so I want to
write about the current state of self-hosting&amp;nbsp;LLMs.&lt;/p&gt;
&lt;p&gt;First, I think it&amp;#8217;s quite amazing that you can run state-of-the-art models on
your own machines. This sets &lt;span class="caps"&gt;AI&lt;/span&gt; apart from technologies like search engines and â€¦&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Peter Bouda</dc:creator><pubDate>Wed, 15 Oct 2025 16:47:00 +0100</pubDate><guid isPermaLink="false">tag:www.peterbouda.eu,2025-10-15:/running-ai-at-home.html</guid><category>AI</category><category>AI</category></item><item><title>ðŸ”¬ Fascinating research from NVIDIA: Small Language Models are the Future of Agentic AI</title><link>https://www.peterbouda.eu/fascinating-research-from-nvidia-small-language-models-are-the-future-of-agentic-ai.html</link><description>&lt;p&gt;While everyone&amp;#8217;s focused on making models bigger, this paper makes a compelling case for going smallerâ€”especially for agentic &lt;span class="caps"&gt;AI&lt;/span&gt;&amp;nbsp;systems.&lt;/p&gt;
&lt;p&gt;The core insight: Most &lt;span class="caps"&gt;AI&lt;/span&gt; agents don&amp;#8217;t need vast general knowledge. They perform specialized, repetitive tasks where fine-tuned small language models (SLMs) are not just sufficientâ€”they â€¦&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Peter Bouda</dc:creator><pubDate>Tue, 30 Sep 2025 10:36:00 +0100</pubDate><guid isPermaLink="false">tag:www.peterbouda.eu,2025-09-30:/fascinating-research-from-nvidia-small-language-models-are-the-future-of-agentic-ai.html</guid><category>AI</category><category>AI</category></item><item><title>Talk about multilingual agentÂ evaluation</title><link>https://www.peterbouda.eu/talk-about-multilingual-agent-evaluation.html</link><description>&lt;p&gt;This Thursday, today, I am happy to give a talk about multilingual agents and their performance on European languages
&lt;a href="https://luma.com/bszaz8e3"&gt;at the &lt;span class="caps"&gt;AI&lt;/span&gt; Agent World Tour: Lisbon MLOps Meetup&lt;/a&gt;. We tested a few LLMs that you can run on
consumer GPUs to find out which work best for agentic use cases â€¦&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Peter Bouda</dc:creator><pubDate>Thu, 11 Sep 2025 09:20:00 +0100</pubDate><guid isPermaLink="false">tag:www.peterbouda.eu,2025-09-11:/talk-about-multilingual-agent-evaluation.html</guid><category>AI</category><category>AI</category></item><item><title>The Great European AI LanguageÂ Championship</title><link>https://www.peterbouda.eu/the-great-european-ai-language-championship.html</link><description>&lt;p&gt;We published &lt;a href="https://substack.com/home/post/p-172471752"&gt;an article today about our multilingual evaluation of smaller LLMs&lt;/a&gt; using the belebele dataset.
&lt;a href="https://github.com/facebookresearch/belebele"&gt;Belebele&lt;/a&gt; is an easy-to-use dataset with multiple choice question in 122 langauge variants, we focussed on 8 European languages.
The gemma-3 models performed best, but open models like OLLMo-2 showed quite good performance, too â€¦&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Peter Bouda</dc:creator><pubDate>Mon, 01 Sep 2025 14:42:00 +0100</pubDate><guid isPermaLink="false">tag:www.peterbouda.eu,2025-09-01:/the-great-european-ai-language-championship.html</guid><category>AI</category><category>AI</category></item><item><title>Running tinygrad with CUDA onÂ NixOS</title><link>https://www.peterbouda.eu/running-tinygrad-with-cuda-on-nixos.html</link><description>&lt;p&gt;I started to play around with NixOS a few weeks ago and until now I am quite happy with it. I installed it on an older
&lt;span class="caps"&gt;PC&lt;/span&gt; with a Geforce &lt;span class="caps"&gt;GT&lt;/span&gt; 1030 and wanted to see if I get tinygrad running with the &lt;span class="caps"&gt;CUDA&lt;/span&gt; back-end on it. I learned about â€¦&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Peter Bouda</dc:creator><pubDate>Mon, 16 Jun 2025 08:40:00 +0100</pubDate><guid isPermaLink="false">tag:www.peterbouda.eu,2025-06-16:/running-tinygrad-with-cuda-on-nixos.html</guid><category>AI</category><category>AI</category></item></channel></rss>